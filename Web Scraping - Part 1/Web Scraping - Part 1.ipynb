{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro To Webscraping\n",
    "\n",
    "We're going to learn how to scrape data from a website. It is quite common that you might want to scrape a bunch of data from a website in order to analyse it. For example:\n",
    "\n",
    " - Scrape a bunch of comments/social media posts to analyze sentiment\n",
    " - Scrape a bunch of data saved as .csv files somewhere\n",
    " - Pull public records that don't have a native download option on the webpage\n",
    " - etc, etc\n",
    " \n",
    "Webscraping is SUPER powerful, because it enables you to create datasets out of almost anything you can find online. We'll walk through a toy example here, and then you can feel free to identify the website of your choice and scrape away!\n",
    "\n",
    "We'll need some tools before we get started:\n",
    "\n",
    "I should point out, there are multiple frameworks to use for webscraping: beautifulsoup/selenium+chromedriver/requests/urlib are all fairly common and are used for different applications. Each scraping task will require slightly different capabilities, and require choosing the correct tooling. We'll focus on the first two here.\n",
    "\n",
    "- First, make sure you have Chrome. You should already, as it's the best browser on the planet :)\n",
    "\n",
    "- Second, download and run the appropriate: <a href=\"https://chromedriver.chromium.org/downloads\">ChromeDriver</a>\n",
    "\n",
    "- Third, make sure you have both selenium and beautifulsoup4\n",
    "\n",
    "\n",
    "## -----------DISCLAIMER!!!-------------WARNING!!!--------------\n",
    "\n",
    "Many websites prohibit webscraping. This is not to say people don't do it all the time anyways, but we'll need to play by the rules here. If you search online, there are many awesome uses/examples/tutorials on webscraping. One common excercise is to scrape Indeed or LinkedIn for job postings in a given city, to figure out the most in demand skills. The problem is, many of the job boards prohibit scraping. So, just for liabilities sake, we're going to do a toy example here. <a href=\"http://toscrape.com\">Toscrape.com</a> is a free website that was specifically set up for scraping, so we can play around with it without worrying about a specific site's Terms of Service changing on us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import selenium and beautifulsoup\n",
    "\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.4/981.4 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from selenium) (1.26.9)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m359.0/359.0 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sniffio in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Requirement already satisfied: idna in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Collecting pyOpenSSL>=0.14\n",
      "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cryptography>=1.3.4\n",
      "  Downloading cryptography-37.0.4-cp36-abi3-macosx_10_10_universal2.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.2/58.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
      "Installing collected packages: sortedcontainers, PySocks, outcome, h11, async-generator, wsproto, trio, cryptography, trio-websocket, pyOpenSSL, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 cryptography-37.0.4 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.3.0 sortedcontainers-2.4.0 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.1.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (4.11.1)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages (from BeautifulSoup4) (2.3.2.post1)\r\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ks/wmyjpklj74bd5vsh426v1w4c0000gp/T/ipykernel_46459/2983289159.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/Users/gamze/Downloads/chromedriver')\n"
     ]
    }
   ],
   "source": [
    "#point selenium to your download of the chromedriver and instantiate a driver\n",
    "\n",
    "driver = webdriver.Chrome('/Users/gamze/Downloads/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test it out and see if it's working\n",
    "\n",
    "driver.get('http://books.toscrape.com/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok - let's get to scraping. Let's build a dataset that has the following for each book:\n",
    "\n",
    "- Title\n",
    "- Price\n",
    "- Description\n",
    "- Rating\n",
    "- Genre\n",
    "\n",
    "We'll use the same general process for each of the above. Web scraping can involve a bit of trial and error. Essentially you're just trying to figure out:\n",
    "- Where does the element you're looking for live in the html?\n",
    "- What is it's tag or XPath?\n",
    "- What is the page structure? I.e, once you've found the tag you want, how can you loop through the whole page to find ALL of the thing you're interested in (like all the titles).\n",
    "\n",
    "## I'll give an example below, then you can replicate it for each additional element you need.\n",
    "\n",
    " - right click one of the titles on the page and click 'inspect'\n",
    " - look at the section of html that pops up and right click that section of html and hover over 'copy'\n",
    " - click 'copy XPath'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll use the find_elements_by_xpath function on the XPath we copied to see what we get:\n",
    "\n",
    "title_element = driver.find_element(\"xpath\", '//*[@id=\"default\"]/div/\\\n",
    "                                              div/div/div/section/div[2]/ol/li[1]/article/h3/a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Light in the ...'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using '.text' on this element will show us the text displayed on the page\n",
    "\n",
    "title = title_element.text\n",
    "title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Light in the Attic'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#that seems truncated - let's look back at the html and see if there's a tag that holds the whole title\n",
    "#get_attribute will help here\n",
    "\n",
    "title = title_element.get_attribute('title')\n",
    "title\n",
    "\n",
    "#there we go!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok - now we've found where each title is stored within the html of the page!\n",
    "\n",
    "Now we need to repeat this process for every book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic! I've scraped 20 titles!\n"
     ]
    }
   ],
   "source": [
    "# lets write a loop that pulls every title for the page and saves it in a list\n",
    "\n",
    "title_list = []\n",
    "\n",
    "for i in range(1,21): #this range represents the number of books per page\n",
    "\n",
    "    title_element = driver.find_element (\"xpath\",'//*[@id=\"default\"]/div/div/div/div/section/\\\n",
    "                                                    div[2]/ol/li[{}]/article/h3/a'.format(i)) #notice the .format()\n",
    "    title_list.append(title_element.get_attribute('title'))\n",
    "    \n",
    "print('Magic! I\\'ve scraped {} titles!'.format(len(title_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Light in the Attic', 'Tipping the Velvet', 'Soumission', 'Sharp Objects', 'Sapiens: A Brief History of Humankind', 'The Requiem Red', 'The Dirty Little Secrets of Getting Your Dream Job', 'The Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull', 'The Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics', 'The Black Maria', 'Starving Hearts (Triangular Trade Trilogy, #1)', \"Shakespeare's Sonnets\", 'Set Me Free', \"Scott Pilgrim's Precious Little Life (Scott Pilgrim #1)\", 'Rip it Up and Start Again', 'Our Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991', 'Olio', 'Mesaerion: The Best Science Fiction Stories 1800-1849', 'Libertarianism for Beginners', \"It's Only the Himalayas\"]\n"
     ]
    }
   ],
   "source": [
    "print (title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magic! I've scraped 1000 titles!\n"
     ]
    }
   ],
   "source": [
    "#the loop above only scraped the first page. let's nest another loop to scrape every page\n",
    "\n",
    "title_list = []\n",
    "\n",
    "for i in range(1,51):\n",
    "\n",
    "    driver.get('http://books.toscrape.com/catalogue/page-{}.html'.format(i))\n",
    "\n",
    "    for x in range(1,21): #this range represents the number of books per page\n",
    "\n",
    "        title_element = driver.find_elements_by_xpath('//*[@id=\"default\"]/div/div/div/div/section/\\\n",
    "                                                        div[2]/ol/li[{}]/article/h3/a'.format(x))[0]\n",
    "        title_list.append(title_element.get_attribute('title'))\n",
    "        \n",
    "#quit your session so you don't have any ghost browsing sessions running :)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print('Magic! I\\'ve scraped {} titles!'.format(len(title_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The way we've done it above actually launches a Chrome GUI browser. This is computationally expensive, and therefore, bad practice. It's cool, because you can follow along and literally see the scraping happening. That said, in practice you'll likely want to do this in what's called a 'headless' manner. Go online and read up on how to run selenium without launching a GUI browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ks/wmyjpklj74bd5vsh426v1w4c0000gp/T/ipykernel_46459/282283343.py:7: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome('/Users/mschuchardt/bin/chromedriver', options=options)\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages/selenium/webdriver/common/service.py:71\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     70\u001b[0m     cmd\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_line_args())\n\u001b[0;32m---> 71\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWindows\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreationflags\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.5/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:969\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    966\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    967\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 969\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/python@3.10/3.10.5/Frameworks/Python.framework/Versions/3.10/lib/python3.10/subprocess.py:1845\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1844\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1845\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/mschuchardt/bin/chromedriver'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m options \u001b[38;5;241m=\u001b[39m Options()\n\u001b[1;32m      6\u001b[0m options\u001b[38;5;241m.\u001b[39mheadless \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m driver \u001b[38;5;241m=\u001b[39m \u001b[43mwebdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChrome\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/mschuchardt/bin/chromedriver\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m title_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m51\u001b[39m):\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages/selenium/webdriver/chrome/webdriver.py:69\u001b[0m, in \u001b[0;36mWebDriver.__init__\u001b[0;34m(self, executable_path, port, options, service_args, desired_capabilities, service_log_path, chrome_options, service, keep_alive)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m service:\n\u001b[1;32m     67\u001b[0m     service \u001b[38;5;241m=\u001b[39m Service(executable_path, port, service_args, service_log_path)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDesiredCapabilities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHROME\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbrowserName\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoog\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mservice_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesired_capabilities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mservice_log_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages/selenium/webdriver/chromium/webdriver.py:89\u001b[0m, in \u001b[0;36mChromiumDriver.__init__\u001b[0;34m(self, browser_name, vendor_prefix, port, options, service_args, desired_capabilities, service_log_path, service, keep_alive)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mservice cannot be None\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice \u001b[38;5;241m=\u001b[39m service\n\u001b[0;32m---> 89\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     93\u001b[0m         command_executor\u001b[38;5;241m=\u001b[39mChromiumRemoteConnection(\n\u001b[1;32m     94\u001b[0m             remote_server_addr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mservice\u001b[38;5;241m.\u001b[39mservice_url,\n\u001b[1;32m     95\u001b[0m             browser_name\u001b[38;5;241m=\u001b[39mbrowser_name, vendor_prefix\u001b[38;5;241m=\u001b[39mvendor_prefix,\n\u001b[1;32m     96\u001b[0m             keep_alive\u001b[38;5;241m=\u001b[39mkeep_alive, ignore_proxy\u001b[38;5;241m=\u001b[39m_ignore_proxy),\n\u001b[1;32m     97\u001b[0m         options\u001b[38;5;241m=\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/homebrew/Cellar/jupyterlab/3.4.3/libexec/lib/python3.10/site-packages/selenium/webdriver/common/service.py:81\u001b[0m, in \u001b[0;36mService.start\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mENOENT:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     82\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable needs to be in PATH. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     83\u001b[0m                 os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message)\n\u001b[1;32m     84\u001b[0m         )\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m err\u001b[38;5;241m.\u001b[39merrno \u001b[38;5;241m==\u001b[39m errno\u001b[38;5;241m.\u001b[39mEACCES:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WebDriverException(\n\u001b[1;32m     87\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m executable may have wrong permissions. \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     88\u001b[0m                 os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpath), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_error_message)\n\u001b[1;32m     89\u001b[0m         )\n",
      "\u001b[0;31mWebDriverException\u001b[0m: Message: 'chromedriver' executable needs to be in PATH. Please see https://chromedriver.chromium.org/home\n"
     ]
    }
   ],
   "source": [
    "#set the options for the driver such that Chrome doesn't actually launch a GUI\n",
    "\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Chrome('/Users/mschuchardt/bin/chromedriver', options=options)\n",
    "\n",
    "\n",
    "title_list = []\n",
    "\n",
    "for i in range(1,51):\n",
    "\n",
    "    driver.get('http://books.toscrape.com/catalogue/page-{}.html'.format(i))\n",
    "\n",
    "    for x in range(1,21): #this range represents the number of books per page\n",
    "\n",
    "        title_element = driver.find_elements_by_xpath('//*[@id=\"default\"]/div/div/div/div/section/\\\n",
    "                                                        div[2]/ol/li[{}]/article/h3/a'.format(x))[0]\n",
    "        title_list.append(title_element.get_attribute('title'))\n",
    "        \n",
    "#quit your session so you don't have any ghost browsing sessions running :)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "print('Magic! I\\'ve scraped {} titles!'.format(len(title_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There we go! We've scraped all 1000 titles. Let's step back for a moment now.\n",
    "\n",
    "Above we did a quick and dirty scrape of every title on the website. We kept it super high level, and never navigated to any individual books's page. In order to pull more data for each book, let's dive in deeper.\n",
    "\n",
    "In this next section we'll first try to figure out if there's a pattern we can follow for each page's link. Then we'll loop through every page and scrape as much as we can from it.\n",
    "\n",
    "The selenium/ChromeDriver toolset is really cool, and helps visually illustrate what a webscraper is doing. In the next lab, we'll use beautifulsoup to get into the weeds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
